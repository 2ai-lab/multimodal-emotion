{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ae687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting giskard>=2.0.0b\n",
      "  Downloading giskard-2.0.0b17-py3-none-any.whl (417 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.6/417.6 kB\u001b[0m \u001b[31m18.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle>=1.1.1\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting zstandard>=0.10.0\n",
      "  Downloading zstandard-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m14.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:02\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25hCollecting mlflow-skinny>=2\n",
      "  Downloading mlflow_skinny-2.6.0-py3-none-any.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m26.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hCollecting numpy<1.24.0,>=1.22.0\n",
      "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m41.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:14\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from giskard>=2.0.0b) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from giskard>=2.0.0b) (1.10.1)\n",
      "Collecting mixpanel>=4.4.0\n",
      "  Downloading mixpanel-4.10.0-py2.py3-none-any.whl (8.9 kB)\n",
      "Requirement already satisfied: requests>=2.19 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from giskard>=2.0.0b) (2.28.1)\n",
      "Requirement already satisfied: pydantic<2,>=1.7 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from giskard>=2.0.0b) (1.10.10)\n",
      "Requirement already satisfied: tqdm>=4.42.0 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from giskard>=2.0.0b) (4.65.0)\n",
      "Requirement already satisfied: setuptools<68.0.0,>=39.1.0 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from giskard>=2.0.0b) (67.6.0)\n",
      "Requirement already satisfied: pandas<2,>=1.3.4 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from giskard>=2.0.0b) (1.5.3)\n",
      "Collecting xxhash>=3.2.0\n",
      "  Downloading xxhash-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m63.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langdetect>=1.0.9\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m47.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m42.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2>=3 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from giskard>=2.0.0b) (3.1.2)\n",
      "Collecting markdown\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m45.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt>=0.9.1\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m37.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting stomp-py>=8.1.0\n",
      "  Downloading stomp.py-8.1.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m48.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from jinja2>=3->giskard>=2.0.0b) (2.1.2)\n",
      "Requirement already satisfied: six in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from langdetect>=1.0.9->giskard>=2.0.0b) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from mixpanel>=4.4.0->giskard>=2.0.0b) (1.26.13)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from mlflow-skinny>=2->giskard>=2.0.0b) (8.1.3)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Downloading databricks-cli-0.17.7.tar.gz (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m42.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: entrypoints<1 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from mlflow-skinny>=2->giskard>=2.0.0b) (0.4)\n",
      "Collecting gitpython<4,>=2.1.0\n",
      "  Downloading GitPython-3.1.35-py3-none-any.whl (188 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.8/188.8 kB\u001b[0m \u001b[31m38.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from mlflow-skinny>=2->giskard>=2.0.0b) (6.0)\n",
      "Collecting protobuf<5,>=3.12.0\n",
      "  Downloading protobuf-4.24.2-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m46.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz<2024 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from mlflow-skinny>=2->giskard>=2.0.0b) (2022.7.1)\n",
      "Requirement already satisfied: packaging<24 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from mlflow-skinny>=2->giskard>=2.0.0b) (23.0)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from mlflow-skinny>=2->giskard>=2.0.0b) (6.1.0)\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m51.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from pandas<2,>=1.3.4->giskard>=2.0.0b) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from pydantic<2,>=1.7->giskard>=2.0.0b) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from requests>=2.19->giskard>=2.0.0b) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from requests>=2.19->giskard>=2.0.0b) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from requests>=2.19->giskard>=2.0.0b) (2023.5.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from scikit-learn>=1.0->giskard>=2.0.0b) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from scikit-learn>=1.0->giskard>=2.0.0b) (3.1.0)\n",
      "Collecting docopt<0.7.0,>=0.6.2\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: websocket-client<2.0.0,>=1.2.3 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from stomp-py>=8.1.0->giskard>=2.0.0b) (1.5.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyjwt>=1.7.0 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from databricks-cli<1,>=0.8.7->mlflow-skinny>=2->giskard>=2.0.0b) (2.7.0)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow-skinny>=2->giskard>=2.0.0b) (3.15.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: langdetect, databricks-cli, docopt\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=dbd47b912afa1890439a56156793edbf14bd6999a33e1c7d47e39ff69ce50422\n",
      "  Stored in directory: /home/usd.local/siddhi.bajracharya/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.17.7-py3-none-any.whl size=143860 sha256=921e7488a98c830f22aca84507010b5915030e451e355fdb53ef5df3591139cf\n",
      "  Stored in directory: /home/usd.local/siddhi.bajracharya/.cache/pip/wheels/6b/97/66/9aea51f102b7bda562817122c900237a84f9f6649942879dd1\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=9fc53c7fe65eb7acc1dbb3dc5abdbc7bf76759ecf47db4a03e8facee31d733a2\n",
      "  Stored in directory: /home/usd.local/siddhi.bajracharya/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "Successfully built langdetect databricks-cli docopt\n",
      "Installing collected packages: docopt, zstandard, xxhash, tabulate, stomp-py, sqlparse, smmap, protobuf, oauthlib, numpy, markdown, langdetect, cloudpickle, chardet, requests-toolbelt, mixpanel, gitdb, databricks-cli, gitpython, mlflow-skinny, giskard\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed chardet-5.2.0 cloudpickle-2.2.1 databricks-cli-0.17.7 docopt-0.6.2 giskard-2.0.0b17 gitdb-4.0.10 gitpython-3.1.35 langdetect-1.0.9 markdown-3.4.4 mixpanel-4.10.0 mlflow-skinny-2.6.0 numpy-1.23.5 oauthlib-3.2.2 protobuf-4.24.2 requests-toolbelt-1.0.0 smmap-5.0.0 sqlparse-0.4.4 stomp-py-8.1.0 tabulate-0.9.0 xxhash-3.3.0 zstandard-0.21.0\n",
      "\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /home/usd.local/siddhi.bajracharya/anaconda3/envs/jupyter/lib/python3.11/site-packages/numpy-1.24.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \"giskard>=2.0.0b\" -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c687e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb0c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from torchaudio.utils import download_asset\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import lightning.pytorch as pl\n",
    "from torchaudio.transforms import *\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import re\n",
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d3f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llogger = CSVLogger(\"emotions\", 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "99e60dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    \"\"\"\n",
    "        Custom dataset class for loading audio dataset.\n",
    "        meta_df: dataframe containing file_name (without \n",
    "                the .wav extension) and the category (labels) \n",
    "        directory: regular expression for the directory to look \n",
    "                for wav files. (e.g. /dataset/speech/*.wav)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, meta_df, directory, **kwargs):\n",
    "        self.meta_df = meta_df\n",
    "        self.directory = directory\n",
    "#         self.transforms = transforms\n",
    "        self.audio_path_list = glob.glob(directory)\n",
    "#         self.signal_trim = signal_trim\n",
    "        category = self.meta_df['category'].unique()\n",
    "        self.t_dict = dict(zip(category,range(len(category))))\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.audio_path_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         t_dict = dict(zip(\n",
    "#                 self.category,\n",
    "#                     range(len(self.category))\n",
    "#                 ))\n",
    "        audio_path = self.audio_path_list[idx]\n",
    "        audio_name = os.path.basename(audio_path).split('.')[0]\n",
    "        targets = self.meta_df.loc[idx,[ 'category']].values[0]\n",
    "        signal, sr = torchaudio.load(audio_path, )\n",
    "        \n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(\"ast-finetuned-audioset-10-10-0.4593\")\n",
    "        \n",
    "        signal =  signal[0]\n",
    "        return feature_extractor(signal, sampling_rate=16000, return_tensors=\"pt\"), self.t_dict[targets]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "545bd96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'IEMOCAP_full_release/Session*/sentences/wav/Ses*/*.wav'\n",
    "files = glob.glob(data_path)\n",
    "file_name = [x.split(os.sep)[-1].split('.')[0] for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e09b6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_paths = 'IEMOCAP_full_release/Session*/dialog/EmoEvaluation/Categorical/Ses*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "921f3072",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(csv_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3844327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_category_from_path(path):\n",
    "    file_name_list = []\n",
    "    emotion_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            file_name_list.append(re.findall('Ses.*[A-Z][0-9]{3}', line)[0])\n",
    "            emotion_list.append(re.findall(':.*;', line)[0][1:-1].lower())\n",
    "    return file_name_list, emotion_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53af3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "category_list = []\n",
    "for file in csv_files:\n",
    "    f, e = get_name_category_from_path(file)\n",
    "    file_list.extend(f)\n",
    "    category_list.extend(e)\n",
    "meta_df = pd.DataFrame(\n",
    "    {\n",
    "        'file':file_list,\n",
    "        'category':category_list\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "090689df",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['category'] = meta_df['category'].str.replace(';.*','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "774d5886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frustration      7489\n",
       "neutral state    6400\n",
       "excited          4358\n",
       "anger            3911\n",
       "sadness          3521\n",
       "happiness        2799\n",
       "other             682\n",
       "surprise          604\n",
       "fear              260\n",
       "disgust            93\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75d7b163",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['frustration', 'excited', 'sadness', 'fear', 'anger',\n",
       "       'neutral state', 'happiness', 'surprise', 'disgust', 'other'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ab7c5a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asset = AudioDataset(meta_df,data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "506f70ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_values': tensor([[[-0.7030, -1.0522, -0.6753,  ..., -1.1763, -1.2540, -1.1932],\n",
       "          [-0.8457, -1.2658, -0.8890,  ..., -1.2107, -1.2378, -1.1702],\n",
       "          [-1.0629, -1.2776, -1.1097,  ..., -1.1437, -1.2557, -1.2330],\n",
       "          ...,\n",
       "          [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670],\n",
       "          [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670],\n",
       "          [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670]]])},\n",
       " 0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c0275055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LighteningModel(pl.LightningModule):\n",
    "    def __init__(self, input_size=48000, num_classes=10, hidden_size = 200, num_heads = 5, num_layers_tx  = 2):\n",
    "        super(LighteningModel, self).__init__()\n",
    "        self.train_r2 = torchmetrics.R2Score()\n",
    "        self.val_r2 = torchmetrics.R2Score()\n",
    "        self.train_auc = torchmetrics.classification.AUROC(task = 'multiclass', num_classes=num_classes)\n",
    "        self.val_auc = torchmetrics.classification.AUROC(task = 'multiclass', num_classes=num_classes)\n",
    "        \n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(\"ast-finetuned-audioset-10-10-0.4593\")\n",
    "        self.sp_model = ASTForAudioClassification.from_pretrained(\"ast-finetuned-audioset-10-10-0.4593\", return_dict=False)\n",
    "        for param in self.sp_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.sp_model.classifier.dense = nn.Linear(768,527)\n",
    "        \n",
    "        self.fc1 = nn.Linear(527, num_classes)\n",
    "        self.dropout = nn.Dropout(.5) \n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,x,):\n",
    "        x = x['input_values'].view(x['input_values'].size(0), 1024,128)\n",
    "        \n",
    "        out = self.sp_model(x, return_dict=False)[0] #256\n",
    "        out = self.dropout(self.fc1(out))\n",
    "#         out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.0001, weight_decay=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        signal, labels = train_batch\n",
    "#         signal = signal['input_values'].view(signal['input_values'].size(0), 1024,128).shape\n",
    "        labels =labels.float().to('cuda:0')\n",
    "        outputs = self(signal).to('cuda:0')#.argmax(1).float()\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        self.train_auc(outputs, labels.int())\n",
    "        self.log('loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_auc', self.train_auc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        signal ,labels = val_batch\n",
    "        labels = labels.float().to('cuda:0')\n",
    "#         signal = signal['input_values'].view(signal['input_values'].size(0), 1024,128).shape\n",
    "        \n",
    "        outputs = self(signal).to('cuda:0')#.argmax(1).float()\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        self.val_auc(outputs, labels.int())\n",
    "        \n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_auc', self.val_auc, on_step=False, on_epoch=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bbc6caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LighteningModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76520a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7d9f4a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f0073a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudioDataset(meta_df,data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "954e7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(dataset, [0.8, 0.2],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d54c5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd9d4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a32ad13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler = WeightedRandomSampler(sample_weights, int(len(train_set)*1.5), replacement=True)\n",
    "train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle = True, num_workers=8, drop_last=True, )\n",
    "test_dataloader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7f3d7482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer( max_epochs=500, gradient_clip_val=0, logger = llogger, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "79091b25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                      | Params\n",
      "--------------------------------------------------------\n",
      "0 | train_r2  | R2Score                   | 0     \n",
      "1 | val_r2    | R2Score                   | 0     \n",
      "2 | train_auc | MulticlassAUROC           | 0     \n",
      "3 | val_auc   | MulticlassAUROC           | 0     \n",
      "4 | sp_model  | ASTForAudioClassification | 86.6 M\n",
      "5 | fc1       | Linear                    | 5.3 K \n",
      "6 | dropout   | Dropout                   | 0     \n",
      "7 | relu      | ReLU                      | 0     \n",
      "--------------------------------------------------------\n",
      "410 K     Trainable params\n",
      "86.2 M    Non-trainable params\n",
      "86.6 M    Total params\n",
      "346.397   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c76a043b51a44d6b6c87a80a88ea2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, test_dataloader, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5418e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "giskard_dataset = giskard.Dataset(\n",
    "    df=train_loader,  # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n",
    "    target=\"Survived\",  # Ground truth variable\n",
    "    name=\"Titanic dataset\", # Optional\n",
    "    cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"]  # Optional, but is a MUST if available. Inferred automatically if not.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec2dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_function(df):\n",
    "    return trainer.predi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a0a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc683330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e58f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
