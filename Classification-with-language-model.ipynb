{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c687e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb0c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from torchaudio.utils import download_asset\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import lightning.pytorch as pl\n",
    "from torchaudio.transforms import *\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import re\n",
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d3f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llogger = CSVLogger(\"emotions\", 'classification-lang-only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545bd96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'IEMOCAP_full_release/Session*/sentences/wav/Ses*/*.wav'\n",
    "files = glob.glob(data_path)\n",
    "file_name = [x.split(os.sep)[-1].split('.')[0] for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09b6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_paths = 'IEMOCAP_full_release/Session*/dialog/EmoEvaluation/Categorical/Ses*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5706aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues_path_reg = 'IEMOCAP_full_release/Session*/dialog/transcriptions/Ses*.txt'\n",
    "dialogues_paths = glob.glob(dialogues_path_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921f3072",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(csv_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f3059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3844327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_category_from_path(path):\n",
    "    file_name_list = []\n",
    "    emotion_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            file_name_list.append(re.findall('Ses.*[A-Z][0-9]{3}', line)[0])\n",
    "            emotion_list.append(re.findall(':.*;', line)[0][1:-1].lower())\n",
    "    return file_name_list, emotion_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52516a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_dial_from_path(path):\n",
    "    file_name_list = []\n",
    "    dial_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            file_name_list.append(re.findall('Ses.*[A-Z][0-9]{3}', line)[0])\n",
    "            dial_list.append(re.findall(':.*', line)[0][1:])\n",
    "    return file_name_list, dial_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53af3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "category_list = []\n",
    "for file in csv_files:\n",
    "    f, e = get_name_category_from_path(file)\n",
    "    file_list.extend(f)\n",
    "    category_list.extend(e)\n",
    "cat_df = pd.DataFrame(\n",
    "    {\n",
    "        'file':file_list,\n",
    "        'category':category_list\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f326d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "dial_list = []\n",
    "for file in dialogues_paths:\n",
    "    try:\n",
    "        f, d = get_name_dial_from_path(file)\n",
    "        file_list.extend(f)\n",
    "        dial_list.extend(d)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "dial_df = pd.DataFrame(\n",
    "    {\n",
    "        'file':file_list,\n",
    "        'dial':dial_list\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "090689df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df['category'] = cat_df['category'].str.replace(';.*','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774d5886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30117,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df['category'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1977ceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Ses04F_script02_2_F000</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>Ses04F_script02_2_F000</td>\n",
       "      <td>frustration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>Ses04F_script02_2_F000</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file     category\n",
       "134   Ses04F_script02_2_F000        anger\n",
       "3892  Ses04F_script02_2_F000  frustration\n",
       "4985  Ses04F_script02_2_F000        other"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df[cat_df['file']=='Ses04F_script02_2_F000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b04b59da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_df = pd.merge(cat_df, dial_df, on = 'file').groupby(['file','category','dial']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75d7b163",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral state', 'surprise', 'anger', 'frustration', 'disgust',\n",
       "       'other', 'sadness', 'happiness', 'fear', 'excited'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99e60dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class AudioDataset(Dataset, ):\n",
    "    \"\"\"\n",
    "        Custom dataset class for loading audio dataset.\n",
    "        meta_df: dataframe containing file_name (without \n",
    "                the .wav extension) and the category (labels) \n",
    "        directory: regular expression for the directory to look \n",
    "                for wav files. (e.g. /dataset/speech/*.wav)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, meta_df, directory,modality = 'all', **kwargs):\n",
    "        self.meta_df = meta_df\n",
    "        self.directory = directory\n",
    "        self.audio_path_list = glob.glob(directory)\n",
    "        category = self.meta_df['category'].unique()\n",
    "        self.t_dict = dict(zip(category,range(len(category))))\n",
    "        self.kwargs = kwargs\n",
    "        self.modality = modality\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_path_list[idx]\n",
    "        audio_name = os.path.basename(audio_path).split('.')[0]\n",
    "        dialogue = self.meta_df.loc[idx,['dial']].values[0]\n",
    "        targets = self.meta_df.loc[idx,[ 'category']].values[0]\n",
    "        audio_feature = None\n",
    "        encoded_text = None\n",
    "        if self.modality == 'audio' :\n",
    "            signal, sr = torchaudio.load(audio_path, )\n",
    "            signal =  signal[0]\n",
    "            audio_feature = feature_extractor(signal, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            feature_extractor = AutoFeatureExtractor.from_pretrained(\"ast-finetuned-audioset-10-10-0.4593\")\n",
    "            \n",
    "            return audio_feature, self.t_dict[targets]\n",
    "            \n",
    "        elif self.modality == 'text':\n",
    "            \n",
    "            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "            encoded_text = tokenizer(dialogue,return_tensors=\"pt\",  padding=\"max_length\", max_length=50, add_special_tokens=True, truncation=True,)\n",
    "            return  encoded_text, self.t_dict[targets]\n",
    "        \n",
    "        else:\n",
    "            signal, sr = torchaudio.load(audio_path, )\n",
    "            signal =  signal[0]\n",
    "            audio_feature = feature_extractor(signal, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            feature_extractor = AutoFeatureExtractor.from_pretrained(\"ast-finetuned-audioset-10-10-0.4593\")\n",
    "            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "            encoded_text = tokenizer(dialogue,return_tensors=\"pt\",  padding=\"max_length\", max_length=50, add_special_tokens=True, truncation=True,)\n",
    "            return audio_feature, encoded_text, self.t_dict[targets]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab7c5a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asset = AudioDataset(meta_df,data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0275055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LighteningModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes=10,):\n",
    "        super(LighteningModel, self).__init__()\n",
    "        self.train_r2 = torchmetrics.R2Score()\n",
    "        self.val_r2 = torchmetrics.R2Score()\n",
    "        self.train_auc = torchmetrics.classification.AUROC(task = 'multiclass', num_classes=num_classes)\n",
    "        self.val_auc = torchmetrics.classification.AUROC(task = 'multiclass', num_classes=num_classes)\n",
    "        \n",
    "        self.val_f1 = torchmetrics.classification.F1Score(task = 'multiclass', num_classes=num_classes, average ='macro')\n",
    "        self.train_f1 = torchmetrics.classification.F1Score(task = 'multiclass', num_classes=num_classes, average ='macro')\n",
    "        \n",
    "        \n",
    "        self.bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "       \n",
    "        for param in self.bert_model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "#         for param in self.bert_model.encoder.layer[-1:].parameters():\n",
    "#             param.requires_grad = True\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
    "        self.fc1 = nn.Linear(768, num_classes)\n",
    "        self.dropout = nn.Dropout(.7) \n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,y):\n",
    "#         x = x['input_values'].view(x['input_values'].size(0), 1024,128)\n",
    "        input_bert = y['input_ids'].view(y['input_ids'].size(0), 50)\n",
    "        atten_bert =  y['attention_mask'].view(y['attention_mask'].size(0), 50)\n",
    "#         sp = self.sp_model(x, return_dict=False)[0] #256\n",
    "        bert, pool = self.bert_model(input_ids = input_bert, attention_mask = atten_bert, return_dict = False)\n",
    "        bert = self.dropout(pool)\n",
    "        out = self.fc1(bert)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.0001, weight_decay=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        dial, labels = train_batch\n",
    "#         signal = signal['input_values'].view(signal['input_values'].size(0), 1024,128).shape\n",
    "        labels =labels.float().to('cuda:0')\n",
    "        outputs = self( dial).to('cuda:0')#.argmax(1).float()\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        self.train_auc(outputs, labels.int())\n",
    "        self.train_f1(outputs, labels.int())\n",
    "        \n",
    "        self.log('loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_auc', self.train_auc, on_step=False, on_epoch=True)\n",
    "        self.log('train_f1', self.train_f1, on_step=False, on_epoch=True)\n",
    "        \n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        dial, labels = val_batch\n",
    "        labels = labels.float().to('cuda:0')\n",
    "#         signal = signal['input_values'].view(signal['input_values'].size(0), 1024,128).shape\n",
    "        \n",
    "        outputs = self(dial).to('cuda:0')#.argmax(1).float()\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        loss = criterion(outputs, labels.long())\n",
    "        self.val_auc(outputs, labels.int())\n",
    "        self.val_f1(outputs, labels.int())\n",
    "        \n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_auc', self.val_auc, on_step=False, on_epoch=True)\n",
    "        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbc6caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = LighteningModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76520a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d9f4a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f0073a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudioDataset(meta_df,data_path, modality = 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cefef7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9989"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f92675f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9989, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "954e7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(dataset, [0.8, 0.2],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a32ad13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler = WeightedRandomSampler(sample_weights, int(len(train_set)*1.5), replacement=True)\n",
    "train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle = True, num_workers=8, drop_last=True, )\n",
    "test_dataloader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f3d7482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer( max_epochs=500, gradient_clip_val=0, logger = llogger, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79091b25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | train_r2   | R2Score           | 0     \n",
      "1 | val_r2     | R2Score           | 0     \n",
      "2 | train_auc  | MulticlassAUROC   | 0     \n",
      "3 | val_auc    | MulticlassAUROC   | 0     \n",
      "4 | val_f1     | MulticlassF1Score | 0     \n",
      "5 | train_f1   | MulticlassF1Score | 0     \n",
      "6 | bert_model | BertModel         | 109 M \n",
      "7 | fc1        | Linear            | 7.7 K \n",
      "8 | dropout    | Dropout           | 0     \n",
      "9 | relu       | ReLU              | 0     \n",
      "-------------------------------------------------\n",
      "7.7 K     Trainable params\n",
      "109 M     Non-trainable params\n",
      "109 M     Total params\n",
      "437.960   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0289851d2c473ca20323d471e03d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, test_dataloader, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dea2c63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>category</th>\n",
       "      <th>dial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses01F_impro01_F000</td>\n",
       "      <td>neutral state</td>\n",
       "      <td>Excuse me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses01F_impro01_F001</td>\n",
       "      <td>neutral state</td>\n",
       "      <td>Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ses01F_impro01_F002</td>\n",
       "      <td>neutral state</td>\n",
       "      <td>Is there a problem?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ses01F_impro01_F002</td>\n",
       "      <td>surprise</td>\n",
       "      <td>Is there a problem?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ses01F_impro01_F003</td>\n",
       "      <td>anger</td>\n",
       "      <td>You did.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>Ses05M_script03_2_M041</td>\n",
       "      <td>anger</td>\n",
       "      <td>You are a vile tempered, wicked living, evil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>Ses05M_script03_2_M042</td>\n",
       "      <td>anger</td>\n",
       "      <td>Oh, you're not going like this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>Ses05M_script03_2_M043</td>\n",
       "      <td>anger</td>\n",
       "      <td>[GARBAGE] No, you're not.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>Ses05M_script03_2_M044</td>\n",
       "      <td>anger</td>\n",
       "      <td>oh! Marry you again? I wouldn't marry you aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>Ses05M_script03_2_M045</td>\n",
       "      <td>anger</td>\n",
       "      <td>You're a wicked little vampire.  And I pray t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9989 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file       category  \\\n",
       "0        Ses01F_impro01_F000  neutral state   \n",
       "1        Ses01F_impro01_F001  neutral state   \n",
       "2        Ses01F_impro01_F002  neutral state   \n",
       "3        Ses01F_impro01_F002       surprise   \n",
       "4        Ses01F_impro01_F003          anger   \n",
       "...                      ...            ...   \n",
       "9984  Ses05M_script03_2_M041          anger   \n",
       "9985  Ses05M_script03_2_M042          anger   \n",
       "9986  Ses05M_script03_2_M043          anger   \n",
       "9987  Ses05M_script03_2_M044          anger   \n",
       "9988  Ses05M_script03_2_M045          anger   \n",
       "\n",
       "                                                   dial  \n",
       "0                                            Excuse me.  \n",
       "1                                                 Yeah.  \n",
       "2                                   Is there a problem?  \n",
       "3                                   Is there a problem?  \n",
       "4                                              You did.  \n",
       "...                                                 ...  \n",
       "9984   You are a vile tempered, wicked living, evil ...  \n",
       "9985                    Oh, you're not going like this.  \n",
       "9986                          [GARBAGE] No, you're not.  \n",
       "9987   oh! Marry you again? I wouldn't marry you aga...  \n",
       "9988   You're a wicked little vampire.  And I pray t...  \n",
       "\n",
       "[9989 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabdfc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
